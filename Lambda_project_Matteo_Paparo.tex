\documentclass[12pt, a4paper]{report}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel} % Language set to Italian
\usepackage{graphicx}       % For images
\usepackage{geometry}       % For page margins
\usepackage{hyperref}       % For hyperlinks
\usepackage{csquotes}       % Recommended for biblatex
\usepackage{listings}       % For code snippets
\usepackage{xcolor}         % For colors
\usepackage{float}          % For figure placement
\usepackage[backend=biber, style=numeric]{biblatex}

% Bibliography source
\addbibresource{references.bib}

% Page setup
\geometry{
    top=2.5cm,
    bottom=2.5cm,
    left=3cm,
    right=2.5cm
}

% Code listing style
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

% Document Info
\title{\textbf{Lambda Project Report}}
\author{Matteo Paparo}
\date{\today}

\begin{document}

% Title Page
\maketitle

% Abstract
\begin{abstract}
    Il seguente elaborato consiste nell'implementazione di un'\textbf{Architettura Lambda} e il suo adattamento alla gestione di dati di natura finanziaria. I dati in questione sono le \textit{criptovalute}, caratterizzate da una grande disponibilità e da oscillazioni dei prezzi molto accentuate in tempi brevi. L'architettura in questione sarà composta da due layer principali: Il \textbf{Batch Layer}, caratterizzato da un'alta latenza e da un'elaborazione completa dei dati, e lo \textbf{Speed Layer}, che si occuperà di processare i dati in tempo reale con una latenza molto bassa. 
    Oltre ai due layer principali, l'architettura prevede un \textbf{Serving Layer}, che si occuperà di fornire le view del Batch Layer. L'obiettivo è effettuare analisi significative sui dati raccolti; per aumentare la qualità dei dati è stato implementato un modello statistico che esegue una fase preliminare di \textit{cleaning}, utilizzando un filtro per la rimozione degli outlier basato sulla \textbf{Regola dei 3.5 Sigma (Z-Score)}, che copre il 99.95\% della distribuzione normale. 
    Infine, per visualizzare tali analisi, è stata implementata una \textbf{Dashboard}, che consente di visualizzare i dati in modo semplice ed intuitivo.\\
\end{abstract}

% Table of Contents
\tableofcontents
\newpage

% Chapters
\chapter{Configurazione}
Per la realizzazione del progetto è stato utilizzato come ambiente di lavoro \textbf{Docker}, che consente di creare dei container isolati per ogni componente dell'Architettura Lambda. In questo modo è stato possibile gestire le dipendenze e le configurazioni in modo semplice ed efficiente.\\ \\
Il docker compose utilizzato per l'implementazione dell'architettura è composto dalle seguenti macro componenti:
\begin{itemize}
    \item Ecosistema \textbf{Hadoop} per la gestione dell'archiviazione e dell'elaborazione dei dati su larga scala.
    \item \textbf{Apache Kafka} come message broker per il disaccoppiamento tra produttore e consumatori, garantendo persistenza e replay dei messaggi.
    \item \textbf{Apache Spark} come motore di elaborazione batch per il calcolo di metriche complesse (OHLC, RSI, Bollinger Bands) e per il training del modello di anomaly detection.
    \item Database \textbf{Cassandra} per la gestione dei dati in tempo reale e l'archiviazione veloce nello Speed Layer.
    \item \textbf{Servizi applicativi}:
        \begin{itemize}
            \item \textbf{Kafka Producer:} Generatore dei dati, che utilizza API (\textit{Coinbase} e \textit{CoinGecko}) e WebSocket (\textit{Binance}) per raccogliere dati sulle criptovalute. 
            Permettono di avere un flusso continuo di dati con oscillazioni che variano da un minimo di 10, con picchi di 80 dati al secondo.
            %\item \textbf{Batch Layer Consumer:} Consuma messaggi da Kafka, e li scrive su HDFS in micro-batch (ogni 1000 messaggi o 120 secondi).
            %\item \textbf{Speed Layer Consumer:} Consuma messaggi da Kafka, filtra le anomalie usando il modello 4-sigma, e scrive i dati puliti su Cassandra.
            %\item \textbf{Spark Scheduler:} Orchestatore che gestisce la fase di calibrazione e avvia periodicamente i job Spark (creazione del modello ogni 5 minuti e aggiornamento dei dati storici ogni 2,5 minuti).
            \item \textbf{Dashboard} per la visualizzazione dei dati raccolti e delle analisi effettuate.
        \end{itemize}
\end{itemize}
Le risorse allocate a Docker Desktop sono 12GB di RAM, 8 CPU e 2 di Swap, per garantire un funzionamento fluido dell'architettura Lambda implementata.\\
Il progetto è stato sviluppato su un MacBook Air con chip M3, 16Gb di RAM e 216Gb di spazio di archiviazione.
\clearpage
\section{Workflow}
Dall'avvio del docker compose, il flusso di lavoro dell'architettura Lambda segue questi passaggi principali:
\begin{enumerate}
    \item Viene effettuata una fase di calibrazione iniziale, ovvero per i primi 5 minuti vengono raccolti i dati senza effettuare alcuna elaborazione, in modo da avere un dataset iniziale sul quale creare il modello per il cleaning dei dati.
    \item Una volta terminata la fase di calibrazione, il producer inizia a inviare i dati al Batch e allo Speed Layer, i quali effettueranno il filtraggio utilizzando il modello statistico appena creato. 
    \item I dati filtrati verranno poi salvati rispettivamente su HDFS e su Cassandra e disponibili per le analisi e la visualizzazione tramite la Dashboard.
\end{enumerate}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{/Users/matteo/Desktop/Report/images/Lambda_architecture.png}
\end{figure}
\chapter{Data Source}
Il responsabile della generazione dei dati è il \textbf{Kafka Producer}, che utilizza diverse API e WebSocket per raccogliere dati sulle criptovalute, che successivamente vengono inviati al Kafka broker, che funge da intermediario tra il produttore e i consumatori.\\ \\
Organizza i file in topic e distribuisce contemporaneamente gli stessi dati a entrambi i layer, attraverso l'uso di consumer dedicati (in questo caso per ogni layer), permettendo così la possibilità di aumentare la \textbf{scalabilità} del sistema.\\ 
Esso mantiene i messaggi per un periodo configurabile (di default 7 giorni) e permette il replay dei dati se necessario, garantendo sempre la consegna dei messaggi, rendendo il sistema più \textbf{robusto} e \textbf{affidabile}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{/Users/matteo/Desktop/Report/images/Data_source.png}
\end{figure}
\section{Configurazione Docker}
Nello specifico l'architettura del Data Source è composta da:
\begin{itemize}
    \item \textbf{Zookeeper}: servizio di coordinamento distribuito utilizzato da Kafka per la gestione della configurazione del cluster, l'elezione del broker leader, il monitoraggio dello stato dei nodi tramite heartbeat e la sincronizzazione dei metadati relativi ai topic e alle partizioni.
    \item \textbf{Kafka}: message broker distribuito che costituisce il nucleo del sistema di messaggistica. Gestisce l'ingestione dei dati dal Producer, la persistenza temporanea dei messaggi e la loro distribuzione ai Consumer dei due layer (Speed e Batch). Nel progetto è stato configurato un singolo broker con un topic dedicato (\texttt{crypto-prices}) per il flusso dei prezzi delle criptovalute.
    \item \textbf{Kafka Producer}: responsabile della generazione e dell'invio dei dati al broker Kafka. Utilizza API pubbliche (\textit{Coinbase} e \textit{CoinGecko}) e WebSocket (\textit{Binance}) per raccogliere dati sulle criptovalute in tempo reale. I dati raccolti includono solamente informazioni sul prezzo.
\end{itemize}
\chapter{Batch Layer}
Il \textbf{Batch Layer} è uno dei tre Layer principali dell'Architettura Lambda, responsabile dell'archiviazione e dell'elaborazione completa dei dati, consentendo di eseguire analisi approfondite sui dati storici. In questa sezione verranno descritte le componenti principali del Batch Layer, le tecnologie utilizzate e le modalità di implementazione.\\ \\
Il \textbf{Batch Layer} è stato implementato utilizzando \textbf{Apache Hadoop} come framework principale per l'archiviazione e \textbf{Apache Spark} per l'elaborazione dei dati. Hadoop consente di gestire grandi quantità di dati in modo distribuito, mentre Spark fornisce un motore di elaborazione veloce e in-memory per l'analisi dei dati.\\ \\
Per adattare il Batch Layer all'analisi delle crypto, è stata rimodulata la sua struttura per permettere analisi frequenti su tutti i dati processati. 
La rimodulazione è mirata alla gestione dei dati e consiste nella formazione di \textit{micro-batch}, ovvero partizioni dimensionali o temporali, create secondo due differenti criteri: aver raggiunto 1500 record, altrimenti dopo 120 secondi forza la creazione del micro-batch, contenente il numero di record raccolti. Le analisi effettuate comprendono il calcolo di metriche di base quali \textbf{min}, \textbf{max}, \textbf{mean}, \textbf{volatility}, oltre a indicatori tecnici avanzati come \textbf{RSI} (Relative Strength Index), \textbf{Bollinger Bands} e \textbf{Momentum}. Viene inoltre tracciato il \textbf{totale dei dati puliti} per monitorare l'efficacia del processo di cleaning. Questi indicatori sono fortemente utilizzati nell'analisi tecnica per valutare le tendenze di mercato e prendere decisioni informate sugli investimenti.\\ \\
In merito alla fase di cleaning, essa non viene effettuata usando un approccio statico, ovvero secondo tutto il micro-batch viene filtrato direttamente con le informazioni contenute nel modello, ma il filtraggio avviene gradualmente. Più precisamente il micro-batch viene ordinato cronologicamente e viene suddiviso in \textbf{chunk} da 150 record. Successivamente ogni chunk viene filtrato e i dati puliti vengono utilizzati per aggiornare il modello, permettendo così che il modello si adatti all'andamento del mercato e possa supportare le oscillazioni del mercato.\clearpage
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{/Users/matteo/Desktop/Report/images/logic_micro_batch.png}
\end{figure}
\noindent
Poichè il numero di record contenuti in ogni micro-batch può variare, poichè ci sta anche un vincolo temporale, il numero di chunk non è detto che sia sempre lo stesso, comportando quindi che l'ultimo abbia un numero minore di record. Anche in questo caso il chunk viene filtrato e i dati puliti vengono utilizzati per aggiornare il modello.
\section{Workflow}
Quindi il workflow di questo layer è dato da: (1) Il \textbf{Batch Consumer} indirizza i dati in arrivo dal Kafka Broker e li scrive su \textbf{HDFS} e li scrive come file \texttt{.jsonl} nella cartella \texttt{/iot-data/incoming}. (2) Lo Spark job \texttt{model\_trainer.py} legge \textbf{esclusivamente} i dati dalla cartella \texttt{/incoming} (finestra temporale corrente), calcola media e deviazione standard per ogni sensore, e salva il modello in \texttt{/models/model.json}. Questo garantisce che il modello rifletta sempre le condizioni di mercato più recenti.
(3) Lo Spark job \texttt{batch\_processor.py} in sequenza esegue il caricamento del modello e filtra le anomalie dai dati grezzi. Calcola le metriche e salva i risultati aggregati in \texttt{/iot-output/spark/date=YYYY-MM-DD}. Archivia i dati filtrati in \texttt{/iot-data/archive} e successivamente elimina i dati dalla cartella \texttt{/incoming} per liberare spazio per i nuovi dati, in modo da evitare di processare dati già elaborati.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{/Users/matteo/Desktop/Report/images/BatchLayer.png}
\end{figure}
\section{Configurazione Docker}
Nello specifico l'architettura del Batch Layer è composta da:
\begin{itemize}
    \item \textbf{Namenode} è il nodo "master" del file system \textbf{HDFS} (Hadoop Distributed File System). Non memorizza i dati reali, ma gestisce i metadati.
    \item \textbf{Datanode} è il nodo "worker" che memorizzano effettivamente i dati. Gestisce lo storage locale e risponde alle richieste di lettura e scrittura dei dati.
    \item \textbf{Spark Scheduler} è l'orchestratore che gestisce i tempi di esecuzione dei job Spark:
        \begin{itemize}
            \item \texttt{model\_trainer.py}: Eseguito solo una volta, dopo 5 minuti dall'avvio dell'architettura, calcola media e deviazione standard per sensore dai dati recenti e salva \texttt{model.json}.
            \item \texttt{batch\_processor.py}: Eseguito in modalità \textit{event-driven}, ovvero ogni volta che viene rilevato un nuovo micro-batch nella cartella \texttt{/incoming}. Elabora i dati, calcola metriche OHLC e indicatori tecnici, aggiorna il modello e archivia i dati processati.
        \end{itemize}
    \item \textbf{Spark Master} è il coordinatore del cluster Spark. Gestisce le risorse e distribuisce i compiti ai nodi worker. Riceve i job Spark e decide quale Worker eseguirà quale task. Monitora lo stato dei worker.
    \item \textbf{Spark Worker}\footnote{Nel progetto sono stati utilizzati 3 nodi Spark Worker, uno per ogni sensore.} è il nodo che esegue i task assegnati dal Master. Si occupa dell'elaborazione dei dati (filter, map, aggregate) che una volta eseguita, invia i risultati al Master.
    \item \textbf{Batch Consumer} è responsabile del consumo dei messaggi dal topic Kafka e della loro scrittura su HDFS. Per sfruttare al meglio le capacità di scrittura di HDFS, i dati vengono accumulati in buffer prima di essere scritti: ogni 1500 messaggi oppure ogni 120 secondi, a seconda di quale condizione si verifica per prima.
\end{itemize}
\chapter{Speed Layer}
Il secondo layer principale che compone l'Architettura Lambda è lo \textit{Speed Layer}, \\
responsabile dell'elaborazione dei dati in tempo reale con una latenza molto bassa. Questo layer è progettato per gestire i dati che richiedono risposte rapide e aggiornamenti frequenti, consentendo di ottenere informazioni tempestive sui dati in arrivo.\\ \\
Lo \textbf{Speed Layer} è stato implementato utilizzando \textbf{Apache Cassandra} come database NoSQL per la gestione dei dati. Cassandra è progettato per gestire enormi quantità di dati su più server, garantendo elevata disponibilità e scalabilità.
Nel caso dello Speed Layer, il dato viene prima filtrato utilizzando lo stesso modello implementato nel Batch Layer, per garantire la coerenza tra i due layer. Successivamente, il dato filtrato viene salvato in una tabella di Cassandra appositamente creata per memorizzare i dati in tempo reale.\\ \\
Rispetto al Batch Layer, l'approccio con il modello è differente, poichè il modello viene aggiornato in memoria ad ogni nuovo dato valido ricevuto, in questo modo il modello si adatta continuamente alle condizioni di mercato più recenti. Utilizza un \textbf{filtro adattivo EMA} (Exponential Moving Average), quindi invece di usare una media fissa, il filtro aggiorna la media e la varianza ad ogni singolo messaggio ricevuto, permettendo l'adattamento istantaneo ai trend di mercato.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{/Users/matteo/Desktop/Report/images/Speed_layer.png}
\end{figure}
\clearpage
\section{Workflow}
Il workflow di questo layer è dato da: (1) Lo \textbf{Speed Consumer} attende che il modello \texttt{model.json} sia disponibile su HDFS (fase di calibrazione). (2) Una volta disponibile, carica le statistiche iniziali e inizializza le strutture EMA in memoria. (3) Per ogni messaggio ricevuto dal Kafka Broker, applica il filtro EMA adattivo: se il dato è valido, lo scrive su Cassandra e aggiorna le statistiche in memoria. (4) Il modello evolve \textbf{autonomamente} senza ulteriori sincronizzazioni con HDFS, garantendo indipendenza dal Batch Layer. (5) I dati vengono resi disponibili per la visualizzazione tramite la Dashboard. \\
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{/Users/matteo/Desktop/Report/images/Speed_layer_1.png}
\end{figure}
\section{Configurazione Docker}
Nello specifico, l'architettura dello Speed Layer è composta da due nodi:
\begin{itemize}
    \item \textbf{Cassandra-seed} è il nodo principale del cluster Cassandra. Quando altri nodi si avviano, contattano il Seed per scoprire la topologia del cluster. Oltre a fare da coordinatore, è un nodo operativo a tutti gli effetti: memorizza i dati nella tabella \texttt{sensor\_data} e risponde alle query della Dashboard.
    \item \textbf{Speed Consumer} è responsabile a consumare i dati dal Broker Kafka, per ogni messaggio applica il filtro EMA adattivo, se il dato è valido, lo scrive su Cassandra e aggiorna il modello EMA in memoria\footnote{Utilizza l'offset \texttt{latest} di Kafka per saltare automaticamente i dati di calibrazione}.
\end{itemize}
\chapter{Serving Layer \& Dashboard}
L'ultima componente dell'Architettura Lambda è il \textbf{Serving Layer}, che funge da interfaccia tra i dati elaborati dai due layer principali (Batch e Speed) e l'utente finale. Il Serving Layer è responsabile della fornitura di dati e analisi in modo efficiente e accessibile, consentendo agli utenti di visualizzare e interagire con i dati raccolti.\\ \\
Il Serving Layer è stato implementato utilizzando \textbf{Flask}, un framework web leggero e flessibile per Python. Flask consente di creare applicazioni web in modo semplice e rapido, rendendolo ideale per la costruzione di interfacce utente per la visualizzazione dei dati.\\ \\
La Dashboard è composta da diversi elementi per mostrare, non solo, il funzionamento dell'architettura, ma anche le sue prestazioni. Nello specifico abbiamo:\\ \\
\textbf{Widget "Real-Time Status"}\\ 
Mostra se i sensori sono attivi e l'ultimo prezzo ricevuto. Dal menù a tendina, in alto a destra è possibile modificare il titolo della cryptovaluta da monitorare.  
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{/Users/matteo/Desktop/Report/images/widget_status.png}
\end{figure}
\noindent
\textbf{Data Processing Stats}\\
Mostra il numero di dati ricevuti fino all'ultimo batch processato, evidenziando il numero di dati totali, dati puliti e anomalie registrate.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{/Users/matteo/Desktop/Report/images/Data_count.png}
\end{figure}
\noindent
\textbf{Daily Metrics}\\
Mostra le metriche giornaliere calcolate dal Batch Layer, sono metriche generali, aggiornati ad ogni micro-batch processato. I dati mostrati variano in base al titolo selezionato.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{/Users/matteo/Desktop/Report/images/daily_stats.png}
\end{figure}
\noindent
\textbf{Real Time Trend}\\
Mostra l'andamento delle cryptovalute in tempo reale, aggiornando ogni minuto il grafico con i nuovi dati ricevuti dallo Speed Layer. Il grafico riporta le ultime 12 ore di dati.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{/Users/matteo/Desktop/Report/images/trend.png}
\end{figure}
\noindent
\textbf{Memory Usage}\\
Mostra l'utilizzo della memoria di Cassandra e HDFS, per monitorare lo stato di salute del sistema di archiviazione.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{/Users/matteo/Desktop/Report/images/usage.png}
\end{figure}
\noindent
\textbf{End-to-End Latency}\\
Misura il tempo totale impiegato per elaborare una richiesta, dalla ricezione del dato fino alla visualizzazione del risultato nella Dashboard.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{/Users/matteo/Desktop/Report/images/endtoend.png}
\end{figure}
\noindent
Questi sono tutti gli elementi che compongono la Dashboard, permettendo di monitorare in tempo reale lo stato dell'architettura Lambda e le performance dei due layer principali.
Il risultato finale è visibile nell'immagine seguente:
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{/Users/matteo/Desktop/Report/images/dashboard_1.png}
\end{figure}
\clearpage
\chapter{Results Analysis}
\section{Batch Layer Analysis}
Dalle analisi condotte, è stato rilevato che il volume dei dati è estremamente costante, mostrando un andamento lineare nel tempo; ciò conferma che il Producer genera dati in modo regolare. Non sono stati rilevati "buchi temporali" sistematici: il tempo medio di riempimento è di 66 secondi (riconducibile al ciclo di 60 sec + overhead di rete/IO), il che rappresenta il comportamento normale del sistema e non un'anomalia. È stato osservato un singolo caso isolato di latenza maggiore (226 secondi), ma il generation rate medio (2.85 KB/s) indica che non vi è perdita di cicli strutturale.
\begin{figure}[H] 
    \centering
    \begin{minipage}[c]{0.4\textwidth}
        \centering
        \includegraphics[width=1.3 \textwidth]{/Users/matteo/Desktop/Report/images/Buffering_time.png} 
    \end{minipage}
    \hfill
    \begin{minipage}[c]{0.45\textwidth}
        Buffering Stats
        \vspace{0.5cm}
        \centering
        \begin{tabular}{|c|c|}
            \hline
            Avg time to fill & 65,98 sec\\ 
            \hline
            Min time & 13 sec \\
            \hline
            Max time & 226 sec \\
            \hline
        \end{tabular}
        \vspace{0.08cm}
        Generation rate 
        \begin{tabular}{|c|c|}
            \hline
            Avg rate & 0.91 batches/min \\ 
            \hline
            Avg throughput & 0.167 MB/min \\
            \hline
        \end{tabular}

    \end{minipage}
\end{figure}
\noindent
Sono stati analizzati 224 batch durante il periodo di test, riportando dimensioni estremamente stabili:
\begin{center}
    \begin{tabular}{|c|c|}
        \hline
        Avg batch size & 187.73 KB\\ 
        \hline
        Min batch size & 56.2 KB\\
        \hline
        CV & 4,81\% \\
        \hline
    \end{tabular}
\end{center}
Il valore minimo della batch size è dato dal primo batch registrato, prima del raggiungimento del regime stazionario (warmup). Inoltre il CV (coefficiente di variazione) molto basso indica una varianza minima tra le dimensioni dei batch, confermando la forte stabilità dei processi.\\ \\
\clearpage
\section{Speed Layer Analysis}
La latenza end-to-end misura il tempo trascorso tra la generazione del dato dal Producer e la sua disponibilità in Cassandra.
%\begin{figure}[H]
%    \begin{minipage}[c]{0.55\textwidth}
%        \centering
%        \includegraphics[width=1 \textwidth]{/Users/matteo/Desktop/Report/images/latency_report_1.png}
%    \end{minipage}
%    \begin{minipage}[c]{0.55\textwidth}
%        \centering
%        \includegraphics[width=1 \textwidth]{/Users/matteo/Desktop/Report/images/latency_report_2.png}
%    \end{minipage}
%\end{figure}
%\begin{center}
%    \begin{tabular}{|c|c|}
%        \hline
%        Metrics & Value\\ 
%        \hline
%        Count & 14335\\
%        \hline
%        Mean & 10.56 ms \\
%        \hline
%        P50 & 8.02 ms \\
%        \hline
%        P90 & 16.68 ms \\
%        \hline
%        P99 & 40.78 ms \\
%        \hline
%        Min & 3.53 ms \\
%        \hline
%        Max & 279.39 ms \\
%        \hline
%    \end{tabular}
%\end{center}
\begin{figure}[H]
    \hspace{-0.5cm}
    \includegraphics[width=1.1\textwidth]{/Users/matteo/Desktop/Report/images/latency_report.png}
\end{figure}
\noindent
Dalla distribuzione della latenza, notiamo che assume una distribuzione leptocurtica con asimmetria positiva. La concentrazione dei valori tra 5-15 ms indica che il pipeline che compone lo Speed Layer opera efficacemente senza colli di bottiglia.
\section{Correlazione Latenza-Batch}
È stata analizzata la correlazione tra gli arrivi dei batch HDFS e la latenza end-to-end dello Speed Layer.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{/Users/matteo/Desktop/Report/images/graph_latency_batch_correlation.png}
\end{figure}
\noindent
Il coefficiente di correlazione è \textbf{0.025}, indicando che non esiste correlazione significativa tra il processing del Batch Layer e le performance dello Speed Layer. Questo conferma il \textbf{corretto isolamento} tra i due layer, fattore caratterizzante di una architettura Lambda.
\chapter{Conclusione}
Il presente progetto ha dimostrato l'efficacia dell'Architettura Lambda nell'elaborazione di dati finanziari caratterizzati da elevata volatilità, come le criptovalute. L'implementazione ha permesso di raggiungere gli obiettivi prefissati, validando le scelte architetturali attraverso metriche concrete.

\section{Risultati Principali}
I risultati ottenuti confermano la solidità dell'architettura implementata:
\begin{itemize}
    \item \textbf{Stabilità del Batch Layer}: Il coefficiente di variazione (CV) del 4.81\% nelle dimensioni dei micro-batch indica un processo di elaborazione estremamente affidabile e prevedibile.
    \item \textbf{Bassa latenza dello Speed Layer}: Con una latenza media di circa 10 ms e un P99 inferiore a 50 ms, il sistema garantisce risposte in tempo reale adeguate al contesto finanziario.
    \item \textbf{Isolamento dei layer}: Il coefficiente di correlazione di 0.025 tra le attività del Batch Layer e le performance dello Speed Layer conferma l'indipendenza progettuale, requisito fondamentale dell'Architettura Lambda.
\end{itemize}

\section{Considerazioni sul Filtro Adattivo}
Il filtro basato sulla regola dei 3.5-sigma si è dimostrato efficace nel bilanciare due esigenze contrastanti: la rimozione delle anomalie e la tolleranza verso le oscillazioni tipiche del mercato delle criptovalute. L'approccio \textit{chunk-based} nel Batch Layer, che aggiorna il modello ogni 150 record, permette un adattamento graduale ai trend di mercato senza compromettere la stabilità delle statistiche.

\section{Sviluppi Futuri}
Possibili evoluzioni del progetto potrebbero includere:
\begin{itemize}
    \item Implementazione di un sistema di \textbf{alerting automatico} per notificare variazioni significative dei prezzi.
    \item Integrazione con sistemi di \textbf{trading algoritmico} per sfruttare le analisi in tempo reale.
    \item Espansione del cluster Cassandra per migliorare la fault tolerance e la scalabilità orizzontale.
    \item Aggiunta di ulteriori indicatori tecnici (MACD, Stochastic Oscillator) per arricchire le analisi.
\end{itemize}

\end{document}